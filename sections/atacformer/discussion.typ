Atacformer introduces a general-purpose transformer-based foundation model for chromatin accessibility data, demonstrating strong performance across a diverse set of tasks, including cell-type clustering, fragment file processing, bulk ATAC-seq embedding, and multimodal integration with RNA-seq. Unlike prior models, Atacformer explicitly tokenizes genomic intervals as discrete units and discards reliance on positional encodings, instead encouraging the model to learn contextual biological relationships directly from data. This aspect of Atacformer directly builds on our previous work with learning genomic region embeddings @Gharavi2021 @Gharavi2024.

One of Atacformer's most impactful contributions is its ability to operate directly on raw fragment files, bypassing the need for intermediate matrix generation. This greatly reduces computational overhead and processing time, making it especially valuable for large-scale or time-sensitive analyses. Compared to existing scATAC pipelines like SnapATAC2 and ArchR, Atacformer achieves comparable biological fidelity while accelerating analysis by 80% in our benchmarks. This positions Atacformer not just as a new method, but as a fundamentally streamlined alternative to conventional workflows.

Our results show that Atacformer's pre-training strategy, based on ELECTRA-style replaced token detection, enables generalization across both single-cell and bulk data. Fine-tuning on BEDbase bulk datasets reveals that Atacformer embeddings encode biological information such as assay type and cell line identity even in the absence of labels. Token-level embeddings are organized by promoter-enhancer distance without ever having seen explicit TSS annotations during training, underscoring the model's ability to infer global regulatory structure from local context alone.

By integrating Atacformer with Geneformer, we further demonstrate Atacformer's extensibility to multimodal contexts. The CRAFT framework highlights that chromatin-accessibility embeddings can align with transcriptomic signals in a shared latent space, enabling cross-modal retrieval and RNA imputation from ATAC alone. This not only expands Atacformer's applicability to joint profiling datasets, but also opens the door for future extensions such as natural language and epigenome integration or DNA methylation-RNA alignment using similar dual-encoder strategies.

While Atacformer achieves strong results with fewer parameters than some contemporary models, several limitations remain. First, the lack of positional encoding--while intentional--may hinder tasks requiring spatial resolution, such as enhancer-promoter linking across large genomic distances. Second, our approach to fragment tokenization is sensitive to the predefined vocabulary and resolution, which could affect generalization across genome builds or non-human species. Finally, our evaluations--particularly in multimodal alignment--were limited to well-annotated datasets; broader assessments in low-quality or noisy settings are needed.

Looking ahead, several avenues for extending Atacformer's capabilities are promising. These include:
- Longer context windows or streaming architectures for encoding ultra-complex single-cell profiles.
- Generative pre-training approaches (e.g. diffusion or masked span prediction) to enable more flexible inference tasks.
- Application to clinical and diagnostic datasets, especially in cancer, where chromatin structure is often perturbed.

In conclusion, Atacformer serves as both a performant model and a software framework for ATAC-seq analysis. Its general-purpose embeddings, fragment-level input pipeline, and compatibility with other models make it a powerful tool for epigenomic research. By bridging bulk and single-cell assays, integrating modalities, and enabling fast and interpretable analysis, Atacformer contributes to the growing ecosystem of foundation models in biology and offers a blueprint for future advances in genomic machine learning.
