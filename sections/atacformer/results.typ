#import "@local/dissertation:0.0.1": figure-caption-extended, todo

=== Atacformer is a new transformer-based foundation model for ATAC-seq data
#figure(
  image("/fig/atacformer/overview/overview.svg"),
  caption: [An overview of the Atacformer architecture and training procedure.]
) <atacformer-overview>
#figure-caption-extended(caption: [*a.* Model architecture and pretraining schematic for Atacformer. Individual cells are tokenized into the model universe, followed by random token replacement. These tokens are then passed to the embedding module, followed by $n$ transformer blocks to generate contextualized embeddings. *b.* Tissue distribution and representation in the scATAC atlas used in Atacformers pretraining. *c.* The Atacformer tokenization strategy. New cells are tokenized into the model vocabulary using interval overlap analysis.
])

Atacformer is a transformer-based @Vaswani2017 foundation model that produces contextualized embeddings of genomic regions. Unlike existing models that are large, rigid, and task-specific, Atacformer is general-purpose and lightweight: users need only provide chromosome coordinates (chromosome, start, end) to begin analysis. By minimizing assumptions about the data and streamlining inputs, Atacformer serves as a fast, efficient backbone that can be adapted to virtually any genomic interval task. Atacformer consists of two main components: a genomic region embedding module and a stacked transformer encoder layer with multi-head attention (@atacformer-overview\A). To train Atacformer, we curated a single-cell ATAC-seq atlas consisting of 1.2 million cells and $>$ 10 billion tokens from 30 tissues (@atacformer-overview\B) @Zhang2021b @Herring2022 @Massoni-Badosa2024 @Lee2023 @Patel2022 @Collin2021. We uniformly processed all raw datasets using a standardized pre-processing pipeline to ensure data integrity and compatibility (see Methods). We used these uniformly processed results to create a unified consensus vocabulary based on our earlier work @Rymuza2024 consisting of 890,704 distinct genomic regions (see Methods).

To tokenize a single cell into a set of dense, low-dimensional embeddings, we first map each accessible region in the cell to a corresponding region in the model's vocabulary through simple interval intersection (@atacformer-overview\C). This process transforms noisy, unstandardized genomic intervals into fixed tokens while preserving the biological significance of co-accessibility patterns. To enable extremely fast, in-memory tokenization that supports modern machine learning workflows, we developed a set of Rust-based tokenizers to be used in conjunction with Atacformer @LeRoy2025.

Atacformer is trained using an ELECTRA-style pre-training objective @Clark2020 (Fig. @atacformer-overview\D) in which Atacformer receives tokenized region sets in which a random subset of tokens are replaced with others sampled from the vocabulary. The model is then tasked with predicting which tokens were replaced. Unless noted, we pre-trained Atacformer using a 45% token replacement rate and a context window of 8,192, as this captures the majority of co-accessible regions in all single-cells in our corpus (@atacformer-context-window-distribution). We refer to this model as atacformer-base. We evaluated atacformer-base to establish a performance baseline, and then fine-tuned it to achieve better performance and enable more flexible downstream analyses.


=== Atacformer can be paired with Geneformer for powerful multiomics analysis
#figure(
  image("/fig/atacformer/craft/craft.svg"),
  caption: [CRAFT is a powerful dual-encoder, multimodal single-cell embedding model.]
) <atacformer-craft>
#figure-caption-extended(caption: [*a.* Schematic of the CRAFT training procedure. (Left) Schematic of a multiomic single-cell dataset showing ATAC and RNA signal jointly profiled in a single cell. (Right) Training step for a single mini-batch of cells. *b.* UMAP visualizations of the single-cell embeddings generated using the ATAC-encoder (left) and the RNA encoder (right). *c.* Schematic of the learned co-embedding space after training. *d.* Heatmap of nearest RNA-embedding neighbors to a single ATAC-embedding cell, organized by cell type. *e.* Schematic of the RNA-decoder training procedure. *f.* PBMC5k dataset clustered using ATAC-embeddings; colored by cell-type. *g.* Heatmaps of PBMC5k dataset, colored by predicted RNA-expression profile for four different marker genes. *h.* Distribution of predicted LYZ expression levels across cell types.
])

We sought to fine-tune Atacformer on a multimodal task. Recent breakthroughs, such as CLIP (@Radford2021a), demonstrate that aligning fundamentally different data types in a shared latent space enables zero-shot transfer and cross-modal retrieval. Inspired by this, we investigated whether Atacformer would benefit from being paired with an encoder of another modality, such as scRNA-seq. To investigate, we developed Contrastive RNA-ATAC Fine-Tuning (CRAFT), a multi-modal model that combines Atacformer with Geneformer, a transcriptome encoder (@Theodoris2023). CRAFT uses contrastive training on multiomic data to create a shared latent space for scATAC-seq and scRNA-seq data. We initialized the model with pre-trained Atacformer and Geneformer models. We then trained CRAFT using a multiomic dataset containing over 106,000 cells profiled with scATAC and scRNA simultaneously (@atacformer-craft\A; see Methods).

UMAP visualizations of ATAC-seq and RNA-seq embeddings were topologically similar, highlighting modality alignment (@atacformer-craft\B). Embeddings maintained biologically meaningful relationships; for example, the distinct groups of monocytes and CD8+ T cells are maintained in both modalities, as is a clear linear trajectory of the stages of red blood cell development from proerythroblast to erythroblast to normoblast . When projected into a single two-dimensional UMAP, modalities separated visually (@atacformer-craft-by-modality); but despite this, nearest neighbors in higher-dimensional spaces preserved biological similarities, allowing accurate cross-modal cell-type alignment (@atacformer-craft\C). To assess biological coherence, we projected ATAC embeddings into the multimodal CRAFT latent space and queried their nearest RNA neighbors. Consistently, the local RNA neighborhoods aligned with the same cell type as the corresponding ATAC embedding. (@atacformer-craft\D).

Next, we assessed whether the aligned ATAC embeddings encoded transcriptomic information by training a small decoder to predict RNA-seq profiles from ATAC embeddings (Methods, @atacformer-craft\E). This should allow us to leverage the joint CRAFT embeddings to predict scRNA-seq outputs from datasets where only scATAC-seq was assayed, or vice versa. We applied this decoder to an unseen scATAC-seq dataset with known labels, labeled with scVI (see methods). UMAP projections of the ATAC embeddings visually separated cells into clusters for T Cell, B Cell, and Monocyte lineages (@atacformer-craft\F), showing that these out-of-sample cells are distinguished by the model. Next, we applied the RNA-seq decoder to predict scRNA-seq profiles. The predicted RNA-seq profiles accurately recapitulated known gene expression differences among these lineages, including cell-type-specific markers. For example, the imputed expression of monocyte marker LYZ was elevated in monocytes; B cell marker MS4A1 was elevated in B cells; T cell marker CD3E was elevated in T cells; cytotoxic cell marker GNLY was elevated in cytotoxic cells(@atacformer-craft\G). Finally, we examined the predicted normalized expressed across cell-types quantitatively. As an example, we show that the monocyte marker LYZ is disproportionately up-regulated in Monocyute-like cells (@atacformer-craft\H). Collectively, these results demonstrate that RNA-seq patterns have been incorporated in the ATAC-seq embeddings of the multi-modal CRAFT model.

In total, these results demonstrate that CRAFT effectively integrates Atacformer embeddings with complementary single-cell models, enabling robust multimodal analysis and cross-modal biological inference. This dual-encoder framework accurately aligns chromatin accessibility and transcriptomic data within a unified latent space, facilitating precise cell-type identification and enhancing the interpretability of single-cell chromatin profiles.
