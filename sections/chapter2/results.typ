#figure(
  image("../../fig/chapter2/benchmarking.svg"),
  caption: [Benchmarking shows that scEmbed is competitive with existing approaches.]
) <scembed-benchmarking>

*a.* Diagram showing 3 steps of the benchmarking process. *b.* UMAP plot of the cell-embeddings produced by scEmbed. *c.* Results of the benchmarking pipeline. scEmbed is competitive with the top methods. We tested three clustering methods: Hierarchical clustering (HC), K means, and Louvain. The clustering results were evaluated using three metrics: Adjusted mutual information (AMI), adjusted rand index (ARI), and homogeneity. *d.* UMAP plots visually showing the resultant clusters of cell embeddings produced by scEmbed following data loss. *e.* Line plots showing the change in three clustering metrics (ARI, AMI, and Homogeneity) as a function of dropout rate. Plots show that scEmbed retains its ability to accurately cluster single cells up to nearly 80% data loss.

#figure(
  image("../../fig/chapter2/projection.svg"),
  caption: [scEmbed enables knowledge transfer to unseen datasets.]
) <scembed-projection>

Transfer learning with scEmbed occurs in three steps. *a.* Diagram showing the high-level workflow of other scATAC-seq methods (top) compared to scEmbed (bottom) *b.* Diagram of the overlap analysis procedure. Using interval overlap analysis, a new cell from a new dataset (blue) can be cast in the feature space of the data used for the pre-trained model (red). *c.* Diagram showing the computation of embeddings for new, unseen data. This is achieved using basic average pooling of region embeddings. *d.* UMAP plots of both projected (right) and unprojected (left) datasets. The plots show nearly identical clustering of embeddings learned from the original dataset versus projection. *e.* RAGI score plots for both the original dataset embeddings and projected cell embeddings. RAGI scores are computed for three clustering methods: Hierarchical clustering, K-means, and Louvain.

=== Overview of the scEmbed architecture 

scEmbed adapts our previous work, Region2Vec @Gharavi2021a, to single cells. The model is a modified unsupervised word2vec @Mikolov2013a model that learns to predict genomic region co-accessibility (@scembed-overview \A). Briefly, scEmbed treats each cell as a document and its accessible regions as words. Context is simulated through by shuffling these regions (@scembed-overview \B). After training, cell embeddings are constructed by averaging region vectors for each cell, which are then used for tasks like clustering, analysis, or transfer learning (@scembed-overview \C). 


=== scEmbed model validation and benchmarking

To validate scEmbed, we followed an earlier approach @Chen2019a to benchmark it on clustering tasks using published reference scATAC data from hematopoietic cells @Buenrostro2018 (@scembed-benchmarking \A). We trained scEmbed for 100 epochs then used the resulting region embeddings to construct cell embeddings. Visually, scEmbed clusters cells of the same type (@scembed-benchmarking \B). We clustered the cell embeddings with three clustering methods: K-means, hierarchical clustering (HC), and Louvain clustering. The clusters were then compared to ground truth labels using three metrics: adjusted rand index (ARI), the adjusted mutual information score (AMI), and the homogeneity score (see Methods). scEmbed performs similar to the best-performing scATAC-seq methods, including SCALE, scBasset, cisTopic, and SnapATAC (@scembed-benchmarking \C). It does so with almost no preprocessing of the data and a completely unsupervised learning workflow. 



=== scEmbed is robust to data loss 

Next we wodnered if we could leverage scEmbed for transfer learning tasks, which can result in a loss of information. As such, we sought to evaluate its ability to cluster data with increasing levels of information loss. To test scEmbed’s robustness to missing data, we trained the model on datasets of increasing sparsity. Starting with the Buenrostro2018 dataset (2.8% non-zero) @Buenrostro2018, we randomly dropped non-zero values in the binary accessibility matrix until approximately 80% of the data was lost. A dropout rate of 80% resulted in a matrix that was 0.5% non-zero. Even at a drop-out rate of 80%, scEmbed was able to visually cluster cells of the same type (@scembed-benchmarking \D). To quanify this, we computed three scores for each dropout dataset: 1) Adjusted Rand Index (ARI), 2) Adjusted Mutual Information (AMI), and 3) Homogeneity scores. We found that scEmbed retained clustering accuracy comparable to other scATAC-seq analysis methods @Chen2019a even when faced with 80% data loss (Fig. @scembed-benchmarking \E). These findings confirm that scEmbed can learn rich biological knowledge, even for the most sparse datasets. The ability to handle sparseness is a critical characteristic of scATAC-seq analysis, and particularly so for scEmbed, which can be used to transfer information from existing models, as we describe next. 




=== Using scEmbed to transfer knowledge of genomic region co-occurrence to unseen datasets 

A key innovation in scEmbed is that it uses a two-step training process, rather than a single step, like many other methods (@scembed-projection \A). In the first step, scEmbed learns embeddings of genomic regions rather than cells. In the second step, the region embeddings are then used to build cell embeddings. In a typical analysis, both steps would use the same input data, corresponding to a typical one-step analysis. Alternatively, the region embeddings can also be used to build cell embeddings for new datasets. This transfer approach allows scEmbed to take advantage of pre-trained reference models. We call this “projection” because we “project” new data into the latent space of the original dataset, creating cell embeddings for new data using a pre-trained model. Projection occurs in three steps: First, we train a model on reference data to produce region embeddings for each region in the reference consensus region set. Second, we take a new single-cell dataset and map the regions to the reference consensus region set using region overlaps (@scembed-projection \B). This represents each single cell in the new dataset using the set of regions from the reference dataset, for which we also have region embeddings from the reference model. Finally, we compute the average of all region embeddings for each cell in the new dataset (@scembed-projection \C).  This approach leverages the information from a larger atlas of accessibility data to analyze a new dataset. In fact, the original training data need not come from scATAC-seq at all. Using this approach, a model trained with bulk ATAC-seq could similarly be used to project scATAC-seq data. This provides an enormous advantage by utilizing the patterns of region co-occurrence from the vast volume of publicly available region set data to inform cell embeddings of single-cell data. 

=== Projected cell embeddings cluster cells accurately using pre-trained models

We next assessed this projection process by asking whether scEmbed could cluster a new dataset based entirely on a pre-trained model.  First, we trained a model on the original Buenrostro2018 dataset @Buenrostro2018; second, we took a new dataset, 10X genomics 5k Peripheral blood mononuclear cells (PBMCs) from a healthy donor, and projected each cell into the original space. We used these single-cell embeddings directly for UMAP visualization and clustering analysis. To assess the quality of the projection, we assumed that ~8 distinct cell populations existed and took advantage of marker gene analysis to assign labels to each cell. We use the Residual Average Gini Index (RAGI) score to evaluate the clustering ability of scEmbed @Chen2019a (Methods). 

We found that the projected-cell analysis showed no marked differences in clustering proficiency when compared to the embeddings produced by conventional model training. The UMAP plots were visually similar (@scembed-projection \D), and the actual evaluation of clustering using the RAGI score showed that the projected dataset may even outperform the model trained on the original data when clustered using either hierarchical clustering or kmeans (@scembed-projection \E). In addition, the time to analyze the new dataset is reduced from hours to minutes, since only overlap analysis and vector algebra is required prior to clustering. 

#figure(
  image("../../fig/chapter2/annotation.svg"),
  caption: [Pre-trained embedding models can be exploited for cell-type annotation tasks.]
) <scembed-annotation>

*a.* Diagram showing scEmbed’s three projection paths. *b.* Overview of the standard “no-projection” data flow. *c.* Overview of three data flows for new data. EV-projection places the new data in the same latent space as the reference data. *d.* UMAP plot of the reference data embeddings built using the standard workflow. *e.* UMAP plot of the new PBMC data with E-projection. *f.* Plots showing the EV-projection data flow applied to the new PBMC dataset. Grey cells represent the reference topology; colored cells are projected new PBMC data. Separate plots depict individual clusters for visual clarity. *g.* Confusion matrix of scEmbed classification results compared to Cellcano. *h.* UMAP plots showing the cell labels assigned by Cellcano (left) and the cell type labels assigned by scEmbed (right).

=== Pre-trained models from reference datasets can be used to annotate cell clusters 

Given the promising results of our initial experiments with pre-trained models, we next sought a way to visualize the projected cells. Furthermore, we reasoned that this approach could be used to annotate cell clusters for the projected cells, allowing us to borrow annotation information from the reference model. To build such a system, we distinguish between three data flows that can occur with scEmbed (@scembed-annotation \A). The first data flow is the *no projection* flow. This is the standard workflow of training a new scEmbed model on some input data and visualizing the resulting embeddings by fitting a UMAP model to reduce the dimensionality to 2. The second data flow is the embedding-only projection workflow (E-projection). In this data flow, new data is embedded using a pre-trained model trained on reference data, as described above. These embeddings may then be visualized by fitting a UMAP model to reduce dimensionality to 2 dimensions. The final data flow, and the novel innovation that accomplishes our goal of reference-based annotation, is the *embedding and visualization workflow* (EV-projection). In this data flow, new data is first embedded using a pre-trained model on reference data, as in E-projection; then, these embeddings are further projected through a UMAP model that was _fit on the reference data embeddings_, rather than newly fit. With the EV-projection flow, plotting the 2-dimensional cell representations on top of the reference data UMAP plot allows one to visualize where in the original embedding space the new data ended up (@scembed-annotation \B). This is possible because the EV-projection re-uses the same topology from the UMAP model fit to the reference data. 

To demonstrate this approach for reference-based visualization and annotation of new data, we built a reference model using the Luekcen2021 multi-omic dataset @Luecken2021, a first-of-its-kind multimodal benchmark dataset of 120,000 single cells from the human bone marrow of 10 diverse donors measured with two commercially available multi-modal technologies. Using scEmbed and the “no projection” data flow, we trained a model and clustered the resulting embeddings (@scembed-annotation \C). This model served as the reference for all downstream experiments with a new PBMC dataset from 10X genomics. Using E-projection, scEmbed creates visually distinct clusters of single cells (@scembed-annotation \D). To visualize these embeddings in the context of the original embedding topology, we employ EV-projection. Each identified cluster from E-projection aggregates to a distinct location in the original UMAP embedding topology of the Luecken2021 model (@scembed-annotation \E). Confident our pre-trained Luecken2021 embedding model was distinctly clustering the new PBMC dataset, we sought to assign cell-type labels to each cluster. We leveraged Cellcano, a new scATAC-seq cell-annotation method, to assign ground-truth labels to each cluster of the E-projected PBMC embeddings for evaluation of our method @Ma2023. Our cell-type annotation system was limited by the cell types annotated in Luecken2021, as such we mapped each scEmbed prediction class to a corresponding Cellcano class for comparison after following their annotation procedure. Using a simple k-nearest-neighbor (KNN) classification algorithm, scEmbed was highly consistent with the Cellcano labels (F1=0.87, @scembed-annotation \F). Without class mapping, scEmbed offers higher specificity of cluster identity and even identifies a cluster of ID2-hi myeloid progenitor cells not found with Cellcano (@scembed-annotation \G). Thus, we conclude that EV-projection is a promising approach for visualization and annotation of new data. Furthermore, the entire process of dimensionality reduction, clustering, and annotation took less than 10 minutes on a laptop. 